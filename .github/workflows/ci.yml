name: Scrape Georgia Legislation

# Trigger configuration
on:
  # Manual trigger - allows running the workflow from GitHub UI
  # Users can optionally specify max_pages parameter to limit scraping
  workflow_dispatch:
    inputs:
      max_pages:
        description: Maximum pages to scrape (leave empty for all pages)
        required: false
        default: ''
  # Scheduled trigger
  schedule:
  - cron: 0 4 * * *

jobs:
  scrape:
    runs-on: ubuntu-latest
    # 2-hour timeout for full session scrapes
    # Adjust if your scraping takes longer
    timeout-minutes: 120

    steps:
    # Step 1: Clone the repository to get the latest code
    - name: Checkout repository
      uses: actions/checkout@v6

    # Step 2: Set up Python 3.11 environment
    # Matches local development requirements
    - name: Set up Python
      uses: actions/setup-python@v6
      with:
        python-version: '3.11'

    # Step 3: Install Python dependencies and Playwright browser
    # - requests: HTTP library for making web requests
    # - beautifulsoup4: HTML parsing library
    # - playwright: Browser automation for JavaScript rendering
    # - aiohttp: Async HTTP client for concurrent requests
    # - chromium: Headless browser for rendering JavaScript-heavy pages
    - name: Install dependencies
      run: |
        pip install requests beautifulsoup4 playwright aiohttp
        playwright install chromium

    # Step 4: Set up Node.js for validation scripts
    - name: Set up Node.js
      uses: actions/setup-node@v6
      with:
        node-version: '20'

    # Step 5: Install Node.js validation tools
    - name: Install Node.js tools
      run: npm install

    # Step 6: Run the scraper
    # - Respectfully scrapes with configurable delays to respect server
    # - Uses environment variables to control request rate
    # - continue-on-error: true allows workflow to continue if server blocks IPs
    # - Outputs ga_legislation.json to repository root
    - name: Run scraper
      continue-on-error: true
      env:
        SCRAPER_DELAY: '2'
        SCRAPER_CONCURRENCY: '2'
      run: |
        if [ -n "${{ github.event.inputs.max_pages }}" ]; then
          echo "Scraping maximum ${{ github.event.inputs.max_pages }} pages..."
          echo "Using respectful settings: 2s delay, 2 concurrent requests"
          python backend/scraper.py ${{ github.event.inputs.max_pages }}
        else
          echo "Scraping all available pages..."
          echo "Using respectful settings: 2s delay, 2 concurrent requests"
          python backend/scraper.py
        fi
        
        # Verify output file location
        if [ -f ga_legislation.json ]; then
          echo "✓ Output file created at repository root"
        else
          echo "⚠ Output file not found at repository root"
          # Check if it was created elsewhere
          find . -name "ga_legislation.json" -type f
        fi

    # Step 7: Verify that output file was created
    # - Sets output variable 'exists' to true/false
    # - Used by subsequent steps to conditionally run
    - name: Check if output file exists
      id: check_file
      run: |
        if [ -f ga_legislation.json ]; then
          echo "exists=true" >> $GITHUB_OUTPUT
          echo "JSON file created successfully"
          echo "File size: $(wc -c < ga_legislation.json) bytes"
        else
          echo "exists=false" >> $GITHUB_OUTPUT
          echo "Warning: JSON file was not created"
        fi

    # Step 8: Validate JSON schema
    # - Validates structure and content against defined schema
    # - Checks required fields, data types, and formats
    # - Reports statistics on valid/invalid bills
    - name: Validate JSON schema
      if: steps.check_file.outputs.exists == 'true'
      run: node scripts/validate-schema.js ga_legislation.json

    # Step 9: Generate timestamp for artifact naming
    # - Used to create unique artifact names for each run
    # - Helps track when data was collected
    - name: Get current date
      id: date
      run: echo "date=$(date +'%Y-%m-%d_%H-%M-%S')" >> $GITHUB_OUTPUT

    # Step 10: Upload results as GitHub Artifact
    # - Only runs if output file was successfully created
    # - Artifacts are retained for 90 days
    # - Can be downloaded from the Actions tab in GitHub
    - name: Upload JSON as artifact
      if: steps.check_file.outputs.exists == 'true'
      uses: actions/upload-artifact@v6
      with:
        name: ga-legislation-${{ steps.date.outputs.date }}
        path: ga_legislation.json
        retention-days: 7

    # Step 11: Create GitHub App token for bypass branch protection
    # Uses the GitHub App credentials to get a token that can bypass
    # branch protection rules and create pull requests
    - name: Generate GitHub App token
      id: app-token
      uses: actions/create-github-app-token@v1
      with:
        app-id: ${{ secrets.APP_ID }}
        private-key: ${{ secrets.PRIVATE_KEY }}
      if: |
        steps.check_file.outputs.exists == 'true' &&
        github.event_name == 'schedule'

    # Step 12: Create feature branch and commit changes
    # Creates a new branch for the data update, commits the changes,
    # and pushes to remote. Uses the GitHub App token for authentication.
    - name: Create pull request with updated data
      if: |
        steps.check_file.outputs.exists == 'true' &&
        github.event_name == 'schedule'
      env:
        GH_TOKEN: ${{ steps.app-token.outputs.token }}
      run: |
        git config --local user.email "github-actions[bot]@users.noreply.github.com"
        git config --local user.name "github-actions[bot]"

        # Create a feature branch with timestamp
        BRANCH_NAME="update-legislation-${{ steps.date.outputs.date }}"
        git checkout -b "$BRANCH_NAME"

        # Add the generated file (force add since it's in .gitignore)
        git add -f ga_legislation.json

        # Check if there are changes to commit
        if ! git diff --cached --quiet; then
          git commit -m "chore: update legislation data - ${{ steps.date.outputs.date }}"
          git push origin "$BRANCH_NAME"

          # Create pull request using GitHub CLI
          gh pr create \
            --base main \
            --head "$BRANCH_NAME" \
            --title "chore: update legislation data - ${{ steps.date.outputs.date }}" \
            --body "Automated legislation data update from web scraper. $(echo 'Date:') ${{ steps.date.outputs.date }}"
        else
          echo "No changes detected in ga_legislation.json"
        fi
